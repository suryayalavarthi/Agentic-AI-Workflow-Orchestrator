# ğŸ¤– Agentic AI Workflow Orchestrator
### Production-Grade Multi-Agent RAG with LangGraph, MCP, & ChromaDB

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/Orchestration-LangGraph-orange)](https://github.com/langchain-ai/langgraph)
[![MCP](https://img.shields.io/badge/Protocol-MCP-green)](https://modelcontextprotocol.io/)
[![ChromaDB](https://img.shields.io/badge/Memory-ChromaDB-lightgrey)](https://www.trychroma.com/)
[![Streamlit](https://img.shields.io/badge/UI-Streamlit-red)](https://streamlit.io/)

A stateful, multi-agent research system designed to automate complex information gathering and synthesis with **hallucination resistance** and **factual grounding**. This orchestrator employs cyclic reasoning to research, analyze, and verify data, producing high-precision reports backed by a local **ChromaDB** vector store.

---

## ï¿½ High-Level Value Proposition

### ğŸ›¡ï¸ Factual Grounding & Hallucination Resistance
Unlike standard LLM chats, this orchestrator never "guesses." If the **Analyst** identifies a gap in the gathered data, it forces the **Researcher** back into the field. All synthesis is cross-referenced against raw tool outputs and vector DB sources.

### ğŸ”Œ Standardized Tooling via MCP
Leveraging the **Model Context Protocol (MCP)**, the system interacts with external tools (Search, Scrapers, Filesystems) through a standardized interface, ensuring decoupled, scalable, and reliable tool execution.

---

## ğŸ—ï¸ System Architecture

The orchestrator utilizes a **Supervisor-Worker** pattern with integrated context compression and recursive guardrails.

```mermaid
flowchart TD
    User([User Prompt]) --> GUI[Streamlit UI]
    GUI --> Graph[LangGraph Orchestrator]
    
    subgraph "Orchestration Loop"
        Supervisor{Supervisor Node}
        Summarizer[Summarizer Node]
        Researcher[Researcher Agent]
        Analyst[Analyst Agent]
        Final[Final Report Node]
    end

    subgraph "Knowledge Stack"
        MCP[FastMCP: Brave/Search/Scraper]
        VectorDB[(ChromaDB)]
    end

    Supervisor -->|eval & route| Researcher
    Researcher -->|Standardized Tools| MCP
    MCP -->|Raw Data| Researcher
    Researcher -->|Persistence| VectorDB

    Researcher --> Analyst
    Analyst -->|Check Memory| VectorDB
    Analyst -->|Gap Detected| Supervisor
    Analyst -->|Sufficient Data| Final

    Final -->|Complete| END([End Session])
    
    Supervisor -.->|Trigger if Context > 6 Msg| Summarizer
    Summarizer -.->|Compressed Context| Supervisor
```

---

## ğŸ§  Technical Deep Dive

### ğŸ§¼ State Hygiene
To prevent "topic bleed" and stale reasoning, the system implements strict state cleanup at the start of every user turn:
- **`messages` Reset**: The message history is cleared for the active turn, keeping only the new query.
- **`research_results` Flush**: Per-turn research artifacts are cleared to ensure the final report reflects the current query's findings.
- **`loop_count` Reset**: Tracking resets to zero to allow a full reasoning cycle for new tasks.

### ğŸ›¡ï¸ Recursive Guardrails
Agentic loops can become expensive or infinite. We implement two layers of protection:
1. **Application Layer (`loop_count`)**: The `Supervisor` and `Analyst` track iterations; if research exceeds 15 steps, the system forces a "Best Effort" synthesis to the `Final Report` node.
2. **Infrastructure Layer (`recursion_limit`)**: LangGraph is configured with a hard `recursion_limit=25`. If the graph exceeds this threshold, execution halts to prevent API rate-limit exhaustion.

### ğŸ“‰ Context Compression
The **Summarizer Node** monitors token pressure. When the message history exceeds 6 entries, it condenses the historical metadata into a `summary` field.
- **Active HumanMessage Preservation**: The summarizer is specifically tuned to purge system metadata while preserving the *last user message*, ensuring the Supervisor never loses sight of the current objective.

---

## ğŸ› ï¸ The Knowledge Stack

- **Orchestration**: [LangGraph](https://github.com/langchain-ai/langgraph) (Stateful, cyclic graph execution).
- **Intelligence**: Anthropic Claude 3.5 Sonnet / Gemini 1.5 Pro.
- **Memory**: [ChromaDB](https://www.trychroma.com/) (Vector store for source-grounded retrieval).
- **Protocol**: [FastMCP](https://github.com/jlowin/fastmcp) (Standardized tool calling interface).

---

## ğŸ“‚ Project Structure

```text
src/
â”œâ”€â”€ agents/             # Specialist logic (Supervisor, Researcher, Analyst)
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ workflow.py     # Graph definition & conditional routing
â”‚   â””â”€â”€ nodes.py        # Shared node implementations (Summarizer, Final Report)
â”œâ”€â”€ mcp_logic/          # MCP Client & Server implementations
â”œâ”€â”€ tools/              # RAG & specialized toolsets (ChromaDB, Search)
â”œâ”€â”€ gui.py              # Streamlit dashboard
â”œâ”€â”€ main.py             # CLI entry point
â””â”€â”€ state.py            # TypedDict state definitions
```

---

## ğŸš€ Installation & Usage

### 1ï¸âƒ£ Prerequisites
- Python 3.10+
- Anthropic or OpenAI API Key
- [Optional] LangSmith API Key for tracing

### 2ï¸âƒ£ Setup
```bash
# Clone the repository
git clone <repo-url>
cd agentic-orchestrator

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3ï¸âƒ£ Configuration
Create a `.env` file in the root directory:
```env
ANTHROPIC_API_KEY=your_key_here
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_key
```

### 4ï¸âƒ£ Execution
**Launch the Dashboard (Recommended):**
```bash
streamlit run src/gui.py
```

**Launch the CLI:**
```bash
python -m src.main
```

---
*Built with precision by the Agentic Workflow Team.*